nohup: 忽略输入
Dataset has size 100
Start from 0
  0%|          | 0/100 [00:00<?, ?it/s]Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /root/.local/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth
epoch 1 PSNR: 16.41326904296875 sigma_y: 1.0 tau: 1.0
epoch 2 PSNR: 18.286611557006836 sigma_y: 1.0 tau: 1.0
epoch 3 PSNR: 21.25870704650879 sigma_y: 1.0 tau: 1.0
epoch 4 PSNR: 21.18360710144043 sigma_y: 1.0 tau: 0.95
epoch 5 PSNR: 23.2907772064209 sigma_y: 1.0 tau: 0.95
epoch 6 PSNR: 25.353200912475586 sigma_y: 1.0 tau: 0.95
epoch 7 PSNR: 25.837556838989258 sigma_y: 0.9341734374999999 tau: 0.8573749999999999
epoch 8 PSNR: 25.979778289794922 sigma_y: 0.8716374999999998 tau: 0.8573749999999999
epoch 9 PSNR: 26.312543869018555 sigma_y: 0.8123078125000001 tau: 0.8573749999999999
epoch 10 PSNR: 26.41614532470703 sigma_y: 0.7561000000000001 tau: 0.7737809374999999
epoch 11 PSNR: 26.897979736328125 sigma_y: 0.7029296875 tau: 0.7350918906249998
epoch 12 PSNR: 27.422292709350586 sigma_y: 0.6527124999999999 tau: 0.6983372960937497
epoch 13 PSNR: 27.45863151550293 sigma_y: 0.6053640625 tau: 0.6983372960937497
epoch 14 PSNR: 27.824583053588867 sigma_y: 0.5608000000000001 tau: 0.6983372960937497
epoch 15 PSNR: 28.12992286682129 sigma_y: 0.5189359375000001 tau: 0.48767497911552943
epoch 16 PSNR: 28.01565933227539 sigma_y: 0.47968750000000004 tau: 0.48767497911552943
epoch 17 PSNR: 27.781667709350586 sigma_y: 0.44297031249999996 tau: 0.3972143184582181
epoch 18 PSNR: 27.989408493041992 sigma_y: 0.40869999999999995 tau: 0.37735360253530714
epoch 19 PSNR: 28.026653289794922 sigma_y: 0.3767921875000001 tau: 0.30735686772502346
epoch 20 PSNR: 28.155851364135742 sigma_y: 0.34716250000000004 tau: 0.27738957312183365
epoch 21 PSNR: 28.171558380126953 sigma_y: 0.3197265625 tau: 0.27738957312183365
epoch 22 PSNR: 28.412010192871094 sigma_y: 0.2944 tau: 0.25034408974245487
epoch 23 PSNR: 28.537073135375977 sigma_y: 0.27109843749999996 tau: 0.25034408974245487
epoch 24 PSNR: 28.635759353637695 sigma_y: 0.24973750000000006 tau: 0.20390682574579033
epoch 25 PSNR: 28.5463809967041 sigma_y: 0.23023281250000002 tau: 0.20390682574579033
epoch 26 PSNR: 28.63904571533203 sigma_y: 0.21250000000000002 tau: 0.16608338398760714
epoch 27 PSNR: 28.730173110961914 sigma_y: 0.1964546875 tau: 0.15777921478822676
epoch 28 PSNR: 28.896562576293945 sigma_y: 0.18201249999999997 tau: 0.14239574134637464
epoch 29 PSNR: 28.947113037109375 sigma_y: 0.16908906250000003 tau: 0.10467395472325498
epoch 30 PSNR: 29.036640167236328 sigma_y: 0.15760000000000002 tau: 0.10467395472325498
epoch 31 PSNR: 29.04771614074707 sigma_y: 0.1474609375 tau: 0.09944025698709223
epoch 32 PSNR: 29.159339904785156 sigma_y: 0.1385875 tau: 0.09944025698709223
epoch 33 PSNR: 29.192256927490234 sigma_y: 0.1308953125 tau: 0.0852575903343082
epoch 34 PSNR: 29.23407554626465 sigma_y: 0.12430000000000002 tau: 0.08099471081759278
epoch 35 PSNR: 29.26946449279785 sigma_y: 0.11871718750000002 tau: 0.08099471081759278
epoch 36 PSNR: 29.3668212890625 sigma_y: 0.11406250000000001 tau: 0.08099471081759278
epoch 37 PSNR: 29.38479995727539 sigma_y: 0.1102515625 tau: 0.08099471081759278
epoch 38 PSNR: 29.38778305053711 sigma_y: 0.1072 tau: 0.08099471081759278
epoch 39 PSNR: 29.387371063232422 sigma_y: 0.1048234375 tau: 0.08099471081759278
epoch 40 PSNR: 29.429330825805664 sigma_y: 0.1030375 tau: 0.08099471081759278
epoch 41 PSNR: 29.548675537109375 sigma_y: 0.1 tau: 0.08099471081759278
epoch 42 PSNR: 29.559919357299805 sigma_y: 0.1 tau: 0.08099471081759278
epoch 43 PSNR: 29.539873123168945 sigma_y: 0.1 tau: 0.08099471081759278
epoch 44 PSNR: 29.629653930664062 sigma_y: 0.1 tau: 0.07694497527671314
epoch 45 PSNR: 29.668182373046875 sigma_y: 0.1 tau: 0.07694497527671314
epoch 46 PSNR: 29.6889705657959 sigma_y: 0.1 tau: 0.07694497527671314
epoch 47 PSNR: 29.6155948638916 sigma_y: 0.1 tau: 0.07309772651287748
epoch 48 PSNR: 29.661739349365234 sigma_y: 0.1 tau: 0.07309772651287748
epoch 49 PSNR: 29.717304229736328 sigma_y: 0.1 tau: 0.07309772651287748
epoch 50 PSNR: 29.74287223815918 sigma_y: 0.1 tau: 0.07309772651287748
epoch 51 PSNR: 29.66537857055664 sigma_y: 0.1 tau: 0.07309772651287748
epoch 52 PSNR: 29.6907958984375 sigma_y: 0.1 tau: 0.07309772651287748
epoch 53 PSNR: 29.747730255126953 sigma_y: 0.1 tau: 0.07309772651287748
epoch 54 PSNR: 29.728164672851562 sigma_y: 0.1 tau: 0.07309772651287748
epoch 55 PSNR: 29.714576721191406 sigma_y: 0.1 tau: 0.07309772651287748
epoch 56 PSNR: 29.76058578491211 sigma_y: 0.1 tau: 0.07309772651287748
epoch 57 PSNR: 29.78116226196289 sigma_y: 0.1 tau: 0.0694428401872336
epoch 58 PSNR: 29.799087524414062 sigma_y: 0.1 tau: 0.0694428401872336
epoch 59 PSNR: 29.805438995361328 sigma_y: 0.1 tau: 0.0694428401872336
epoch 60 PSNR: 29.821121215820312 sigma_y: 0.1 tau: 0.0694428401872336
epoch 61 PSNR: 29.86526870727539 sigma_y: 0.1 tau: 0.0694428401872336
epoch 62 PSNR: 29.860172271728516 sigma_y: 0.1 tau: 0.0694428401872336
epoch 63 PSNR: 29.858734130859375 sigma_y: 0.1 tau: 0.0694428401872336
epoch 64 PSNR: 29.840879440307617 sigma_y: 0.1 tau: 0.0694428401872336
epoch 65 PSNR: 29.850513458251953 sigma_y: 0.1 tau: 0.0694428401872336
epoch 66 PSNR: 29.89997100830078 sigma_y: 0.1 tau: 0.0694428401872336
epoch 67 PSNR: 29.904712677001953 sigma_y: 0.1 tau: 0.0626721632689783
epoch 68 PSNR: 29.944297790527344 sigma_y: 0.1 tau: 0.0626721632689783
epoch 69 PSNR: 29.917095184326172 sigma_y: 0.1 tau: 0.0626721632689783
epoch 70 PSNR: 29.958919525146484 sigma_y: 0.1 tau: 0.0626721632689783
epoch 71 PSNR: 29.946880340576172 sigma_y: 0.1 tau: 0.0626721632689783
epoch 72 PSNR: 29.982738494873047 sigma_y: 0.1 tau: 0.059538555105529384
epoch 73 PSNR: 29.955097198486328 sigma_y: 0.1 tau: 0.059538555105529384
epoch 74 PSNR: 29.946231842041016 sigma_y: 0.1 tau: 0.059538555105529384
epoch 75 PSNR: 29.909988403320312 sigma_y: 0.1 tau: 0.059538555105529384
epoch 76 PSNR: 29.914541244506836 sigma_y: 0.1 tau: 0.059538555105529384
epoch 77 PSNR: 29.912303924560547 sigma_y: 0.1 tau: 0.059538555105529384
epoch 78 PSNR: 29.941137313842773 sigma_y: 0.1 tau: 0.059538555105529384
epoch 79 PSNR: 29.97270393371582 sigma_y: 0.1 tau: 0.059538555105529384
epoch 80 PSNR: 29.965301513671875 sigma_y: 0.1 tau: 0.059538555105529384
epoch 81 PSNR: 29.958492279052734 sigma_y: 0.1 tau: 0.059538555105529384
epoch 82 PSNR: 29.95874786376953 sigma_y: 0.1 tau: 0.059538555105529384
epoch 83 PSNR: 29.928396224975586 sigma_y: 0.1 tau: 0.059538555105529384
epoch 84 PSNR: 29.949703216552734 sigma_y: 0.1 tau: 0.059538555105529384
epoch 85 PSNR: 29.899887084960938 sigma_y: 0.1 tau: 0.05656162735025291
main_sampling.py:521: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  LPIPS = loss_fn_vgg(2*orig-1.0, 2*torch.tensor(x[j]).to(torch.float32).cuda()-1.0)[0,0,0,0]
PSNR:29.8731 (0.0894), SSIM:0.79375 (0.00255), LPIPS:0.23003 (0.00338):   0%|          | 0/100 [10:54<?, ?it/s]PSNR:29.8731 (0.0894), SSIM:0.79375 (0.00255), LPIPS:0.23003 (0.00338):   1%|          | 1/100 [10:54<18:00:22, 654.77s/it]epoch 1 PSNR: 16.53317642211914 sigma_y: 1.0 tau: 1.0
epoch 2 PSNR: 18.023088455200195 sigma_y: 1.0 tau: 1.0
epoch 3 PSNR: 20.139225006103516 sigma_y: 1.0 tau: 1.0
epoch 4 PSNR: 20.94872283935547 sigma_y: 1.0 tau: 1.0
PSNR:29.8731 (0.0894), SSIM:0.79375 (0.00255), LPIPS:0.23003 (0.00338):   1%|          | 1/100 [11:09<18:24:16, 669.26s/it]
Traceback (most recent call last):
  File "main_sampling.py", line 1041, in <module>
    sample_image(opt=opt, config=config, model_config=model_config, device=device)
  File "main_sampling.py", line 483, in sample_image
    xt = hmc(x, n, b, seq, seq_next, algo, opt, y_0, H_funcs, x_orig)
  File "main_sampling.py", line 838, in hmc
    loss_grad = torch.autograd.grad(loss, x_proposal, retain_graph=False)[0]
  File "/root/miniconda3/envs/NHMC/lib/python3.8/site-packages/torch/autograd/__init__.py", line 436, in grad
    result = _engine_run_backward(
  File "/root/miniconda3/envs/NHMC/lib/python3.8/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/root/miniconda3/envs/NHMC/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 852874) is killed by signal: Terminated. 
