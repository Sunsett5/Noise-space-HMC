nohup: 忽略输入
Dataset has size 100
Start from 0
sigma_y = opt.sigma_0 + 0.9 * (1 - epoch / epochs) ** 3
  0%|          | 0/100 [00:00<?, ?it/s]Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /root/.local/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth
epoch 1 PSNR: 16.444168090820312 sigma_y: 1.0 tau: 1.0
epoch 2 PSNR: 18.074548721313477 sigma_y: 0.9129666666666666 tau: 1.0
epoch 3 PSNR: 20.929561614990234 sigma_y: 0.8317333333333334 tau: 1.0
epoch 4 PSNR: 21.808006286621094 sigma_y: 0.7561000000000001 tau: 0.9025
epoch 5 PSNR: 24.242626190185547 sigma_y: 0.6858666666666667 tau: 0.7350918906249998
epoch 6 PSNR: 25.841520309448242 sigma_y: 0.6208333333333335 tau: 0.6302494097246091
epoch 7 PSNR: 26.467849731445312 sigma_y: 0.5608000000000001 tau: 0.6302494097246091
epoch 8 PSNR: 26.876934051513672 sigma_y: 0.5055666666666666 tau: 0.6302494097246091
epoch 9 PSNR: 27.288387298583984 sigma_y: 0.4549333333333334 tau: 0.5688000922764596
epoch 10 PSNR: 27.792518615722656 sigma_y: 0.40869999999999995 tau: 0.5688000922764596
epoch 11 PSNR: 27.703472137451172 sigma_y: 0.3666666666666668 tau: 0.41812033521917696
epoch 12 PSNR: 28.145809173583984 sigma_y: 0.32863333333333333 tau: 0.41812033521917696
epoch 13 PSNR: 28.229534149169922 sigma_y: 0.2944 tau: 0.3235335449737089
epoch 14 PSNR: 28.468460083007812 sigma_y: 0.26376666666666665 tau: 0.25034408974245487
epoch 15 PSNR: 28.35027313232422 sigma_y: 0.23653333333333335 tau: 0.25034408974245487
epoch 16 PSNR: 28.692459106445312 sigma_y: 0.21250000000000002 tau: 0.25034408974245487
epoch 17 PSNR: 28.478620529174805 sigma_y: 0.19146666666666667 tau: 0.1937114844585008
epoch 18 PSNR: 28.661178588867188 sigma_y: 0.17323333333333335 tau: 0.18402591023557577
epoch 19 PSNR: 28.639484405517578 sigma_y: 0.15760000000000002 tau: 0.16608338398760714
epoch 20 PSNR: 28.927398681640625 sigma_y: 0.1443666666666667 tau: 0.16608338398760714
epoch 21 PSNR: 28.9039306640625 sigma_y: 0.13333333333333336 tau: 0.1352759542790559
epoch 22 PSNR: 28.94657325744629 sigma_y: 0.12430000000000002 tau: 0.1352759542790559
epoch 23 PSNR: 28.974040985107422 sigma_y: 0.11706666666666668 tau: 0.1352759542790559
epoch 24 PSNR: 29.10857391357422 sigma_y: 0.11143333333333333 tau: 0.11018311023500525
epoch 25 PSNR: 29.192678451538086 sigma_y: 0.1072 tau: 0.11018311023500525
epoch 26 PSNR: 29.180034637451172 sigma_y: 0.10416666666666667 tau: 0.11018311023500525
epoch 27 PSNR: 29.263704299926758 sigma_y: 0.10213333333333334 tau: 0.11018311023500525
epoch 28 PSNR: 29.310617446899414 sigma_y: 0.1009 tau: 0.11018311023500525
epoch 29 PSNR: 29.414661407470703 sigma_y: 0.10026666666666667 tau: 0.11018311023500525
epoch 30 PSNR: 29.4700984954834 sigma_y: 0.10003333333333334 tau: 0.11018311023500525
epoch 31 PSNR: 29.562685012817383 sigma_y: 0.1 tau: 0.04401266686517654
epoch 32 PSNR: 29.58390235900879 sigma_y: 0.1 tau: 0.04401266686517654
epoch 33 PSNR: 29.54248046875 sigma_y: 0.1 tau: 0.04401266686517654
epoch 34 PSNR: 29.604198455810547 sigma_y: 0.1 tau: 0.04401266686517654
epoch 35 PSNR: 29.56850814819336 sigma_y: 0.1 tau: 0.04401266686517654
epoch 36 PSNR: 29.52679443359375 sigma_y: 0.1 tau: 0.04401266686517654
epoch 37 PSNR: 29.551227569580078 sigma_y: 0.1 tau: 0.04401266686517654
epoch 38 PSNR: 29.562360763549805 sigma_y: 0.1 tau: 0.04401266686517654
epoch 39 PSNR: 29.611454010009766 sigma_y: 0.1 tau: 0.04401266686517654
epoch 40 PSNR: 29.674013137817383 sigma_y: 0.1 tau: 0.04401266686517654
epoch 41 PSNR: 29.694793701171875 sigma_y: 0.1 tau: 0.039721431845821824
epoch 42 PSNR: 29.821311950683594 sigma_y: 0.1 tau: 0.039721431845821824
epoch 43 PSNR: 29.785953521728516 sigma_y: 0.1 tau: 0.039721431845821824
epoch 44 PSNR: 29.76590347290039 sigma_y: 0.1 tau: 0.039721431845821824
epoch 45 PSNR: 29.776668548583984 sigma_y: 0.1 tau: 0.039721431845821824
epoch 46 PSNR: 29.751659393310547 sigma_y: 0.1 tau: 0.039721431845821824
epoch 47 PSNR: 29.719131469726562 sigma_y: 0.1 tau: 0.039721431845821824
epoch 48 PSNR: 29.793540954589844 sigma_y: 0.1 tau: 0.039721431845821824
epoch 49 PSNR: 29.70106315612793 sigma_y: 0.1 tau: 0.037735360253530734
epoch 50 PSNR: 29.761653900146484 sigma_y: 0.1 tau: 0.035848592240854196
epoch 51 PSNR: 29.775400161743164 sigma_y: 0.1 tau: 0.035848592240854196
epoch 52 PSNR: 29.762704849243164 sigma_y: 0.1 tau: 0.035848592240854196
epoch 53 PSNR: 29.778060913085938 sigma_y: 0.1 tau: 0.035848592240854196
epoch 54 PSNR: 29.804786682128906 sigma_y: 0.1 tau: 0.035848592240854196
epoch 55 PSNR: 29.900362014770508 sigma_y: 0.1 tau: 0.035848592240854196
epoch 56 PSNR: 29.862648010253906 sigma_y: 0.1 tau: 0.035848592240854196
epoch 57 PSNR: 29.91788673400879 sigma_y: 0.1 tau: 0.035848592240854196
epoch 58 PSNR: 29.84736442565918 sigma_y: 0.1 tau: 0.035848592240854196
epoch 59 PSNR: 29.89385414123535 sigma_y: 0.1 tau: 0.035848592240854196
epoch 60 PSNR: 29.84585189819336 sigma_y: 0.1 tau: 0.035848592240854196
epoch 61 PSNR: 29.88004493713379 sigma_y: 0.1 tau: 0.035848592240854196
epoch 62 PSNR: 29.893150329589844 sigma_y: 0.1 tau: 0.035848592240854196
epoch 63 PSNR: 29.916522979736328 sigma_y: 0.1 tau: 0.035848592240854196
epoch 64 PSNR: 29.864078521728516 sigma_y: 0.1 tau: 0.035848592240854196
epoch 65 PSNR: 29.907379150390625 sigma_y: 0.1 tau: 0.035848592240854196
epoch 66 PSNR: 29.9569149017334 sigma_y: 0.1 tau: 0.035848592240854196
epoch 67 PSNR: 29.869348526000977 sigma_y: 0.1 tau: 0.035848592240854196
epoch 68 PSNR: 29.905454635620117 sigma_y: 0.1 tau: 0.035848592240854196
epoch 69 PSNR: 29.88946533203125 sigma_y: 0.1 tau: 0.035848592240854196
epoch 70 PSNR: 29.89896583557129 sigma_y: 0.1 tau: 0.035848592240854196
main_sampling.py:521: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  LPIPS = loss_fn_vgg(2*orig-1.0, 2*torch.tensor(x[j]).to(torch.float32).cuda()-1.0)[0,0,0,0]

PSNR:29.8314 (0.0720), SSIM:0.80434 (0.00131), LPIPS:0.24596 (0.00261):   0%|          | 0/100 [10:34<?, ?it/s]
PSNR:29.8314 (0.0720), SSIM:0.80434 (0.00131), LPIPS:0.24596 (0.00261):   1%|          | 1/100 [10:34<17:26:56, 634.51s/it]
PSNR:29.8314 (0.0720), SSIM:0.80434 (0.00131), LPIPS:0.24596 (0.00261):   1%|          | 1/100 [10:42<17:40:08, 642.51s/it]
Traceback (most recent call last):
  File "main_sampling.py", line 1037, in <module>
    sample_image(opt=opt, config=config, model_config=model_config, device=device)
  File "main_sampling.py", line 483, in sample_image
    xt = hmc(x, n, b, seq, seq_next, algo, opt, y_0, H_funcs, x_orig)
  File "main_sampling.py", line 833, in hmc
    xt = iterative_sampling(x_proposal, n, b, seq, seq_next, algo, opt, y_0, tqdm_disable=True).clip(-1, 1)
  File "main_sampling.py", line 899, in iterative_sampling
    t = (torch.ones(n) * i).to(xt.device)
  File "/root/miniconda3/envs/NHMC/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 276329) is killed by signal: Terminated. 
